{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entity Extraction (NER) Model Training\n",
        "\n",
        "This notebook trains a Named Entity Recognition (NER) model to extract entities from business documents:\n",
        "- Invoice numbers\n",
        "- Amounts\n",
        "- Dates\n",
        "- Email addresses\n",
        "- Phone numbers\n",
        "- Tax IDs\n",
        "- Company names\n",
        "\n",
        "## Approach\n",
        "1. **Option A:** spaCy NER model (pre-trained + fine-tuning)\n",
        "2. **Option B:** Transformers (BERT-based NER)\n",
        "3. **Option C:** Regex + Rule-based (fast, no training needed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required dependencies (run this first)\n",
        "!pip install pandas numpy spacy transformers torch datasets\n",
        "!python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import re\n",
        "import json\n",
        "from typing import Dict, List\n",
        "\n",
        "# Set paths\n",
        "BASE_DIR = Path('../')\n",
        "DATA_DIR = BASE_DIR / 'data'\n",
        "MODELS_DIR = BASE_DIR / 'models' / 'entity_extractor'\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Base directory: {BASE_DIR}\")\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"Models directory: {MODELS_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample training data with entity annotations\n",
        "sample_documents = [\n",
        "    {\n",
        "        'text': 'Invoice #INV-001\\nDate: 2024-01-15\\nAmount: $1,500.00\\nEmail: contact@company.com\\nPhone: 555-1234',\n",
        "        'entities': {\n",
        "            'invoice_number': 'INV-001',\n",
        "            'date': '2024-01-15',\n",
        "            'amount': '$1,500.00',\n",
        "            'email': 'contact@company.com',\n",
        "            'phone': '555-1234'\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'text': 'Purchase Order PO-2024-001\\nSupplier: ABC Corp\\nOrder Date: 01/20/2024\\nTotal: $5,000.00',\n",
        "        'entities': {\n",
        "            'po_number': 'PO-2024-001',\n",
        "            'company_name': 'ABC Corp',\n",
        "            'date': '01/20/2024',\n",
        "            'amount': '$5,000.00'\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'text': 'Receipt #RCP-789\\nPayment Date: 2024-02-01\\nAmount Paid: $750.25\\nTax ID: 12-3456789',\n",
        "        'entities': {\n",
        "            'receipt_number': 'RCP-789',\n",
        "            'date': '2024-02-01',\n",
        "            'amount': '$750.25',\n",
        "            'tax_id': '12-3456789'\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(sample_documents)\n",
        "print(f\"✓ Created {len(df)} sample documents with entity annotations\")\n",
        "print(f\"\\nSample document:\")\n",
        "print(df.iloc[0]['text'])\n",
        "print(f\"\\nEntities:\")\n",
        "print(df.iloc[0]['entities'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Method A: Rule-based Entity Extraction (Fast, No Training)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_entities_rule_based(text: str) -> Dict[str, List[str]]:\n",
        "    \"\"\"Extract entities using regex patterns\"\"\"\n",
        "    entities = {\n",
        "        'invoice_numbers': re.findall(r'(?:invoice|inv)[\\s#:]*([A-Z0-9\\-]+)', text, re.IGNORECASE),\n",
        "        'po_numbers': re.findall(r'(?:po|purchase\\s*order)[\\s#:]*([A-Z0-9\\-]+)', text, re.IGNORECASE),\n",
        "        'amounts': re.findall(r'\\$[\\d,]+\\.?\\d*', text),\n",
        "        'dates': re.findall(r'\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\\d{4}[/-]\\d{1,2}[/-]\\d{1,2}', text),\n",
        "        'emails': re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text),\n",
        "        'phones': re.findall(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b', text),\n",
        "        'tax_ids': re.findall(r'(?:tax\\s*id|ein|vat)[\\s#:]*([A-Z0-9\\-]+)', text, re.IGNORECASE),\n",
        "    }\n",
        "    return {k: v for k, v in entities.items() if v}\n",
        "\n",
        "# Test\n",
        "test_text = df.iloc[0]['text']\n",
        "extracted = extract_entities_rule_based(test_text)\n",
        "print(f\"Text: {test_text}\")\n",
        "print(f\"\\nExtracted entities:\")\n",
        "for entity_type, values in extracted.items():\n",
        "    print(f\"  {entity_type}: {values}\")\n",
        "\n",
        "# Save rule-based extractor\n",
        "import pickle\n",
        "with open(MODELS_DIR / 'rule_based_extractor.pkl', 'wb') as f:\n",
        "    pickle.dump(extract_entities_rule_based, f)\n",
        "print(f\"\\n✓ Rule-based extractor saved to {MODELS_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Method B: spaCy NER (Pre-trained Model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import spacy\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    \n",
        "    def extract_entities_spacy(text: str) -> Dict[str, List[str]]:\n",
        "        \"\"\"Extract entities using spaCy NER\"\"\"\n",
        "        doc = nlp(text)\n",
        "        entities = {\n",
        "            'persons': [],\n",
        "            'organizations': [],\n",
        "            'dates': [],\n",
        "            'money': [],\n",
        "            'emails': [],\n",
        "            'phones': []\n",
        "        }\n",
        "        \n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ == 'PERSON':\n",
        "                entities['persons'].append(ent.text)\n",
        "            elif ent.label_ == 'ORG':\n",
        "                entities['organizations'].append(ent.text)\n",
        "            elif ent.label_ == 'DATE':\n",
        "                entities['dates'].append(ent.text)\n",
        "            elif ent.label_ == 'MONEY':\n",
        "                entities['money'].append(ent.text)\n",
        "        \n",
        "        # Also extract emails and phones with regex\n",
        "        entities['emails'] = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
        "        entities['phones'] = re.findall(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b', text)\n",
        "        \n",
        "        return {k: v for k, v in entities.items() if v}\n",
        "    \n",
        "    # Test\n",
        "    test_text = df.iloc[0]['text']\n",
        "    extracted = extract_entities_spacy(test_text)\n",
        "    print(f\"Text: {test_text}\")\n",
        "    print(f\"\\nExtracted entities (spaCy):\")\n",
        "    for entity_type, values in extracted.items():\n",
        "        print(f\"  {entity_type}: {values}\")\n",
        "    \n",
        "    # Save\n",
        "    with open(MODELS_DIR / 'spacy_extractor.pkl', 'wb') as f:\n",
        "        pickle.dump(extract_entities_spacy, f)\n",
        "    print(f\"\\n✓ spaCy extractor saved to {MODELS_DIR}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"spaCy not available: {e}\")\n",
        "    print(\"Install with: pip install spacy && python -m spacy download en_core_web_sm\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
