{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sentiment Analysis Model Training\n",
        "\n",
        "This notebook trains a model to analyze sentiment in customer communications (emails, reviews, feedback, etc.)\n",
        "\n",
        "## Approach\n",
        "1. **Option A:** Fine-tuned Transformer (DistilBERT) - Better accuracy\n",
        "2. **Option B:** Traditional ML (TF-IDF + SVM/Naive Bayes) - Faster, works on CPU\n",
        "\n",
        "We'll implement both and compare.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required dependencies (run this first)\n",
        "!pip install pandas numpy scikit-learn matplotlib seaborn transformers torch datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set paths\n",
        "BASE_DIR = Path('../')\n",
        "DATA_DIR = BASE_DIR / 'data'\n",
        "MODELS_DIR = BASE_DIR / 'models' / 'sentiment_analyzer'\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Base directory: {BASE_DIR}\")\n",
        "print(f\"Data directory: {DATA_DIR}\")\n",
        "print(f\"Models directory: {MODELS_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load training data\n",
        "import sys\n",
        "sys.path.insert(0, str(Path('../../')))\n",
        "\n",
        "from ml.utils.data_loader import load_sentiment_data\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Loading sentiment analysis training data...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "try:\n",
        "    df = load_sentiment_data()\n",
        "    \n",
        "    # Safety check\n",
        "    if df is None or len(df) == 0:\n",
        "        print(\"⚠️ No data loaded. Creating sample data...\")\n",
        "        df = pd.DataFrame({\n",
        "            'text': [\n",
        "                'Thank you for the excellent service!',\n",
        "                'Great product, very satisfied!',\n",
        "                'I am very disappointed with the quality',\n",
        "                'This is terrible, I want a refund',\n",
        "                'The order was delivered on time',\n",
        "                'Outstanding customer support!',\n",
        "                'Poor quality, not worth the money',\n",
        "                'Average product, nothing special',\n",
        "                'Highly recommend this product!',\n",
        "                'Worst experience ever'\n",
        "            ],\n",
        "            'label': ['positive', 'positive', 'negative', 'negative', 'neutral',\n",
        "                     'positive', 'negative', 'neutral', 'positive', 'negative']\n",
        "        })\n",
        "    \n",
        "    print(f\"\\n✓ Dataset loaded successfully!\")\n",
        "    print(f\"  Shape: {df.shape}\")\n",
        "    print(f\"\\n  Label distribution:\")\n",
        "    print(df['label'].value_counts())\n",
        "    print(f\"\\n  First few samples:\")\n",
        "    print(df.head())\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error: {e}\")\n",
        "    print(\"Creating sample data...\")\n",
        "    df = pd.DataFrame({\n",
        "        'text': [\n",
        "            'Thank you for the excellent service!',\n",
        "            'Great product, very satisfied!',\n",
        "            'I am very disappointed with the quality',\n",
        "            'This is terrible, I want a refund',\n",
        "            'The order was delivered on time'\n",
        "        ],\n",
        "        'label': ['positive', 'positive', 'negative', 'negative', 'neutral']\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
        ")\n",
        "\n",
        "# Vectorize text\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train Naive Bayes model\n",
        "print(\"Training Naive Bayes classifier...\")\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = nb_model.predict(X_test_vec)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=nb_model.classes_, yticklabels=nb_model.classes_)\n",
        "plt.title('Confusion Matrix - Naive Bayes')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.savefig(MODELS_DIR / 'nb_confusion_matrix.png')\n",
        "plt.show()\n",
        "\n",
        "# Save model\n",
        "from ml.utils.model_saver import save_model\n",
        "save_model(nb_model, vectorizer, MODELS_DIR, accuracy)\n",
        "\n",
        "print(f\"\\nModel saved to {MODELS_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with new text\n",
        "test_texts = [\n",
        "    \"I love this product! It's amazing!\",\n",
        "    \"This is the worst service I've ever experienced\",\n",
        "    \"The product arrived on time and works as expected\"\n",
        "]\n",
        "\n",
        "for text in test_texts:\n",
        "    test_vec = vectorizer.transform([text])\n",
        "    pred = nb_model.predict(test_vec)[0]\n",
        "    proba = nb_model.predict_proba(test_vec)[0]\n",
        "    confidence = max(proba)\n",
        "    \n",
        "    print(f\"\\nText: {text}\")\n",
        "    print(f\"Prediction: {pred}\")\n",
        "    print(f\"Confidence: {confidence:.2%}\")\n",
        "    print(f\"All probabilities:\")\n",
        "    for label, prob in zip(nb_model.classes_, proba):\n",
        "        print(f\"  {label}: {prob:.2%}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
